# Implementa√ß√£o de Aprendizado Sem Pesos

## Status Atual

‚úÖ **Implementado**:
- `WeightlessLearner`: Sistema base de aprendizado estrutural
- `PatternCompressor`: Compress√£o de padr√µes frequentes
- Integra√ß√£o com sistema de mem√≥ria epis√≥dica existente

## Como Funciona

### 1. Armazenamento de Epis√≥dios

```python
from nsr.weightless_learning import WeightlessLearner, Episode
from nsr import run_text_full, SessionCtx

learner = WeightlessLearner()

# Ap√≥s cada execu√ß√£o, armazena epis√≥dio
session = SessionCtx()
outcome = run_text_full("O carro tem rodas", session)

episode_fp = learner.add_episode(
    input_text="O carro tem rodas",
    input_struct=outcome.isr.relations[0],  # Simplificado
    output_text=outcome.answer,
    output_struct=outcome.isr.answer,
    relations=outcome.isr.relations,
    context=outcome.isr.context,
    quality=outcome.quality,
)
```

### 2. Extra√ß√£o de Padr√µes

```python
# Ap√≥s acumular muitos epis√≥dios, extrai padr√µes
patterns = learner.extract_patterns(min_support=5)

for pattern in patterns:
    print(f"Padr√£o: {pattern.structure}")
    print(f"Frequ√™ncia: {pattern.frequency}")
    print(f"Confian√ßa: {pattern.confidence}")
```

### 3. Aprendizado de Regras

```python
# Aprende regras a partir de padr√µes
rules = learner.learn_rules_from_patterns()

# Regras podem ser adicionadas ao SessionCtx
session.kb_rules = tuple(rules)
```

### 4. Busca de Epis√≥dios Similares

```python
# Quando recebe nova entrada, busca epis√≥dios similares
from nsr.parser import build_struct
from nsr.lex import tokenize, DEFAULT_LEXICON

tokens = tokenize("A bicicleta tem pedais", DEFAULT_LEXICON)
query_struct = build_struct(tokens, language="pt")

similar = learner.find_similar_episodes(query_struct, k=5)

# Usa respostas similares como base
if similar:
    best_match = similar[0]
    # Adapta resposta do epis√≥dio similar
```

## Integra√ß√£o com Sistema Atual

### Modificar `runtime.py`

```python
# Em run_text_full, ap√≥s processar:
from nsr.weightless_learning import WeightlessLearner

# Carrega learner (ou cria novo)
learner = get_or_create_learner(session)

# Armazena epis√≥dio
learner.add_episode(
    input_text=text,
    input_struct=meta.struct_node,
    output_text=outcome.answer,
    output_struct=outcome.isr.answer,
    relations=outcome.isr.relations,
    context=outcome.isr.context,
    quality=outcome.quality,
)

# Periodicamente, extrai padr√µes e aprende regras
if len(learner.episodes) % 100 == 0:
    patterns = learner.extract_patterns()
    new_rules = learner.learn_rules_from_patterns(patterns)
    # Adiciona regras ao session
    session.kb_rules = tuple(list(session.kb_rules) + new_rules)
```

## Compara√ß√£o: Sem Pesos vs LLM

### Capacidades Esperadas

| Tarefa | LLM (com pesos) | Sistema Sem Pesos | Status |
|--------|----------------|-------------------|--------|
| **Compreens√£o b√°sica** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚úÖ Implement√°vel |
| **Gera√ß√£o de texto** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚ö†Ô∏è Limitado |
| **Racioc√≠nio l√≥gico** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Superior |
| **Mem√≥ria expl√≠cita** | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Superior |
| **Interpretabilidade** | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Superior |
| **Aprendizado cont√≠nuo** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Superior |
| **Escalabilidade** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚ö†Ô∏è Requer otimiza√ß√£o |

### Limita√ß√µes do Sistema Sem Pesos

1. **Generaliza√ß√£o Cont√≠nua**
   - LLMs: Interpolam suavemente entre conceitos
   - Sem Pesos: Discreto, precisa de regras expl√≠citas
   - **Solu√ß√£o**: Hierarquias de abstra√ß√£o multi-n√≠vel

2. **Nuances de Linguagem**
   - LLMs: Capturam sutilezas impl√≠citas
   - Sem Pesos: Precisa padr√µes expl√≠citos
   - **Solu√ß√£o**: Padr√µes multi-n√≠vel + contexto rico

3. **Criatividade**
   - LLMs: Podem gerar texto criativo
   - Sem Pesos: Limitado a combina√ß√µes de padr√µes
   - **Solu√ß√£o**: Sistema de recombina√ß√£o de padr√µes

## Pr√≥ximos Passos

### Fase 1: Escalabilidade (Atual)
- [x] Sistema base de aprendizado
- [x] Compress√£o de padr√µes
- [ ] √çndices eficientes para busca
- [ ] Persist√™ncia de epis√≥dios

### Fase 2: Generaliza√ß√£o Avan√ßada
- [ ] Alinhamento estrutural multi-n√≠vel
- [ ] Hierarquias de abstra√ß√£o
- [ ] Sistema de vari√°veis inteligente

### Fase 3: Integra√ß√£o Completa
- [ ] Integra√ß√£o com `runtime.py`
- [ ] Aprendizado cont√≠nuo em background
- [ ] Sistema de avalia√ß√£o de regras

### Fase 4: Otimiza√ß√µes
- [ ] Compress√£o agressiva de mem√≥ria
- [ ] Cache inteligente
- [ ] Paraleliza√ß√£o

## Conclus√£o

**√â poss√≠vel** criar um sistema de aprendizado poderoso sem pesos, mas:

‚úÖ **Vantagens**:
- Totalmente interpret√°vel
- Aprendizado cont√≠nuo sem retreinamento
- Mem√≥ria expl√≠cita e audit√°vel
- Controle determin√≠stico

‚ö†Ô∏è **Desafios**:
- Requer mem√≥ria massiva
- Busca pode ser lenta
- Generaliza√ß√£o menos suave que LLMs

üéØ **Resultado Esperado**:
- **N√£o** alcan√ßar√° exatamente o mesmo n√≠vel de LLMs em gera√ß√£o de texto
- **Pode** ser superior em racioc√≠nio l√≥gico e interpretabilidade
- **Ser√°** complementar: melhor para tarefas que exigem controle e auditoria

O sistema atual j√° tem as bases. Falta escalar, otimizar e integrar completamente.
